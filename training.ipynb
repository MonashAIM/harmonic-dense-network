{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the directory\n",
    "#import sys\n",
    "#sys.path.insert(0,'/fs04/sq58/Hardnet/harmonic-dense-network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs04/sq58/Hardnet/harmonic-dense-network\n"
     ]
    }
   ],
   "source": [
    "cd '/fs04/sq58/Hardnet/harmonic-dense-network/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.visualize import blend_images\n",
    "from monai.transforms import Compose, Activations, AsDiscrete\n",
    "from monai.losses import DiceCELoss\n",
    "from src.utils.train_utils import HardUnetTrainer\n",
    "from src.data.ISLES_dataset_2D import ISLESDataModule_2D\n",
    "from src.data.covid_dataset import CovidDataModule\n",
    "from src.models.mseg_hardnet import HarDMSEG\n",
    "from src.models.FCHardnet import FCHardnet\n",
    "import torch\n",
    "import json\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import torch.nn as nn\n",
    "from monai.losses import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#wandb.init(project=\"awa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sq58/mbui0018/conda/envs/hardnet/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# datamodule = ISLESDataModule(data_properties=data, batch_size=1, device=device)\n",
    "with open(fr'./src/data/ISLES_dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "datamodule = ISLESDataModule_2D(batch_size=64, data_properties=data, num_workers=5)\n",
    "# # Total image to read in. In this case, it's 10 (for both train and val). With split = 0.7, 7 wll go to train and 3 will go to val\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 192, 192])\n",
      "tensor([0., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# #Loadin the data according to the upper parameters\n",
    "train_loader = datamodule.train_dataloader()\n",
    "\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    print(batch[\"image\"].shape)\n",
    "    print(torch.unique(batch[\"label\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 11 17:21:52 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:C2:00.0 Off |                    0 |\n",
      "| N/A   29C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sq58/mbui0018/conda/envs/hardnet/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "unet = FCHardnet(n_classes=1, in_channels=1).to(device)\n",
    "lr = 0.002\n",
    "momentum = 0.9\n",
    "decay = 0.0005\n",
    "opt = torch.optim.AdamW\n",
    "sched = torch.optim.lr_scheduler.ConstantLR\n",
    "loss = DiceLoss\n",
    "\n",
    "model = HardUnetTrainer(model=unet, roi_size_h=64, roi_size_w=64, lr=lr, optim=opt, sched=sched, decay=decay, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/scratch/sq58/mbui0018/conda/envs/hardnet/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type      | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | net  | FCHardnet | 4.1 M  | train\n",
      "1 | loss | DiceLoss  | 0      | train\n",
      "-------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.472    Total estimated model params size (MB)\n",
      "309       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sq58/mbui0018/conda/envs/hardnet/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  22%|██▏       | 10/45 [00:02<00:07,  4.41it/s, v_num=5, mean_train_dice=0.293, train_loss=0.821] "
     ]
    }
   ],
   "source": [
    "# initialize Lightning's trainer.\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=600,\n",
    "    check_val_every_n_epoch=20,\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "count = 0\n",
    "unet = unet.to(device)\n",
    "for val_data in val_loader:\n",
    "    if count == 11:\n",
    "          break\n",
    "    print(\"------------ INDEX: \", count, \"----------------\")\n",
    "    val_images, val_labels = val_data[\"image\"].float().to(device), val_data[\"label\"].float().to(device)\n",
    "    blend_img = blend_images(val_images[0],val_labels[0])\n",
    "    outputs = unet(val_images)\n",
    "    post_trans_output = [post_trans(i) for i in outputs]\n",
    "    blend_out = blend_images(val_images[0],post_trans_output[0])\n",
    "    blend_check = blend_images(val_labels[0],post_trans_output[0])\n",
    "\n",
    "    plt.figure()\n",
    "    f, axarr = plt.subplots(1,5)\n",
    "    axarr[0].imshow((blend_img.cpu()).permute(1, 2, 0))\n",
    "    axarr[0].set_title(\"1\")\n",
    "    axarr[0].set_axis_off()\n",
    "\n",
    "    axarr[1].imshow((outputs[0].detach().cpu()).permute(1, 2, 0))\n",
    "    axarr[1].set_title(\"2\")\n",
    "    axarr[1].set_axis_off()\n",
    "\n",
    "    axarr[2].imshow((post_trans_output[0].detach().cpu()).permute(1, 2, 0))\n",
    "    axarr[2].set_title(\"3\")\n",
    "    axarr[2].set_axis_off()\n",
    "\n",
    "    axarr[3].imshow((blend_out.cpu()).permute(1, 2, 0))\n",
    "    axarr[3].set_title(\"4\")\n",
    "    axarr[3].set_axis_off()\n",
    "\n",
    "    axarr[4].imshow((blend_check.cpu()).permute(1, 2, 0))\n",
    "    axarr[4].set_title(\"5\")\n",
    "    axarr[4].set_axis_off()\n",
    "    plt.show()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
